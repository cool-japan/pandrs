//! Comprehensive tests for the statistical computing framework
//!
//! This test module validates all statistical functionality including hypothesis testing,
//! probability distributions, non-parametric methods, and descriptive statistics.

use pandrs::dataframe::DataFrame;
use pandrs::series::Series;
use pandrs::stats::{
    // Hypothesis testing
    one_sample_ttest, independent_ttest, paired_ttest, one_way_anova,
    chi_square_test_independence, correlation_test, shapiro_wilk_test,
    adjust_p_values, AlternativeHypothesis, MultipleComparisonCorrection,
    
    // Distributions
    Distribution, Normal, StandardNormal, TDistribution, ChiSquared, FDistribution,
    Binomial, Poisson,
    
    // Non-parametric tests
    mann_whitney_u_advanced as mann_whitney_u_test, wilcoxon_signed_rank_test, kruskal_wallis_test,
    friedman_test, ks_two_sample_test, runs_test, bootstrap_confidence_interval,
    permutation_test,
    
    // Descriptive statistics
    advanced_descriptive::{describe, pearson_correlation, spearman_correlation, 
                         correlation_matrix, covariance_matrix, percentile},
    
    // High-level interface
    StatisticalAnalyzer, CorrelationMethod, HypothesisTestType, OutlierMethod,
};

#[test]
fn test_comprehensive_hypothesis_testing() {
    // Test one-sample t-test
    let data = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0];
    let result = one_sample_ttest(&data, 5.5, AlternativeHypothesis::TwoSided).unwrap();
    
    assert_eq!(result.test_name, "One-sample t-test");
    assert!(result.p_value > 0.05); // Should not reject null (mean = 5.5)
    assert!(!result.reject_null);
    assert!(result.effect_size.is_some());
    assert!(result.confidence_interval.is_some());
    
    // Test independent samples t-test
    let group1 = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let group2 = vec![3.0, 4.0, 5.0, 6.0, 7.0];
    let result = independent_ttest(&group1, &group2, AlternativeHypothesis::TwoSided, true).unwrap();
    
    assert!(result.test_name.contains("t-test"));
    assert!(result.effect_size.is_some());
    assert!(result.confidence_interval.is_some());
    assert!(result.degrees_of_freedom.is_some());
    
    // Test paired t-test
    let before = vec![10.0, 12.0, 14.0, 16.0, 18.0];
    let after = vec![11.0, 13.0, 15.0, 17.0, 19.0];
    let result = paired_ttest(&before, &after, AlternativeHypothesis::TwoSided).unwrap();
    
    assert_eq!(result.test_name, "Paired samples t-test");
    assert!(result.additional_info.contains_key("mean_before"));
    assert!(result.additional_info.contains_key("mean_after"));
    
    // Test one-way ANOVA
    let group1 = vec![1.0, 2.0, 3.0];
    let group2 = vec![4.0, 5.0, 6.0];
    let group3 = vec![7.0, 8.0, 9.0];
    let groups = vec![group1.as_slice(), group2.as_slice(), group3.as_slice()];
    let result = one_way_anova(&groups).unwrap();
    
    assert_eq!(result.test_name, "One-way ANOVA");
    assert!(result.reject_null); // Groups are clearly different
    assert!(result.effect_size.is_some());
    assert!(result.additional_info.contains_key("eta_squared"));
}

#[test]
fn test_chi_square_and_correlation() {
    // Test chi-square test of independence (using new API)
    let observed = vec![
        vec![10.0, 15.0, 25.0],
        vec![20.0, 10.0, 15.0],
    ];
    let result = chi_square_test_independence(&observed).unwrap();
    
    assert_eq!(result.test_name, "Chi-square test of independence");
    assert!(result.degrees_of_freedom.is_some());
    assert!(result.effect_size.is_some());
    assert!(result.additional_info.contains_key("cramers_v"));
    
    // Test correlation test
    let x = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0];
    let y = vec![2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0]; // Perfect correlation
    let result = correlation_test(&x, &y, AlternativeHypothesis::TwoSided).unwrap();
    
    assert_eq!(result.test_name, "Pearson correlation test");
    assert!((result.additional_info["correlation"] - 1.0).abs() < 1e-10);
    assert!(result.reject_null); // Should reject null of no correlation
    assert!(result.confidence_interval.is_some());
}

#[test]
fn test_normality_and_multiple_comparisons() {
    // Test Shapiro-Wilk normality test
    let normal_data = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0];
    let result = shapiro_wilk_test(&normal_data).unwrap();
    
    assert_eq!(result.test_name, "Shapiro-Wilk normality test (approximation)");
    assert!(result.additional_info.contains_key("note")); // Indicates approximation
    
    // Test multiple comparison corrections
    let p_values = vec![0.01, 0.02, 0.03, 0.04, 0.05];
    
    // Bonferroni correction
    let bonferroni = adjust_p_values(&p_values, MultipleComparisonCorrection::Bonferroni).unwrap();
    assert!((bonferroni[0] - 0.05).abs() < 1e-10); // 0.01 * 5 = 0.05
    assert!((bonferroni[4] - 0.25).abs() < 1e-10); // 0.05 * 5 = 0.25
    
    // Holm-Bonferroni correction
    let holm = adjust_p_values(&p_values, MultipleComparisonCorrection::HolmBonferroni).unwrap();
    assert!(holm.len() == p_values.len());
    
    // Benjamini-Hochberg FDR correction
    let bh = adjust_p_values(&p_values, MultipleComparisonCorrection::BenjaminiHochberg).unwrap();
    assert!(bh.len() == p_values.len());
}

#[test]
fn test_probability_distributions() {
    // Test Standard Normal distribution
    let std_normal = StandardNormal::new();
    
    // PDF at 0 should be 1/sqrt(2Ï€)
    assert!((std_normal.pdf(0.0) - 0.3989422804014327).abs() < 1e-10);
    
    // CDF at 0 should be 0.5
    assert!((std_normal.cdf(0.0) - 0.5).abs() < 1e-10);
    
    // Inverse CDF at 0.5 should be 0
    assert!((std_normal.inverse_cdf(0.5) - 0.0).abs() < 1e-10);
    
    // Mean and variance
    assert_eq!(std_normal.mean(), 0.0);
    assert_eq!(std_normal.variance(), 1.0);
    
    // Test Normal distribution
    let normal = Normal::new(10.0, 2.0);
    assert_eq!(normal.mean(), 10.0);
    assert_eq!(normal.variance(), 4.0);
    assert!((normal.cdf(10.0) - 0.5).abs() < 1e-10); // CDF at mean should be 0.5
    
    // Test t-distribution
    let t_dist = TDistribution::new(10.0);
    assert_eq!(t_dist.mean(), 0.0);
    assert!(t_dist.variance() > 1.0); // Should be > 1 for df > 2
    assert!((t_dist.cdf(0.0) - 0.5).abs() < 0.1); // Should be approximately symmetric
    
    // Test Chi-squared distribution
    let chi_sq = ChiSquared::new(5.0);
    assert_eq!(chi_sq.mean(), 5.0);
    assert_eq!(chi_sq.variance(), 10.0);
    assert_eq!(chi_sq.pdf(-1.0), 0.0); // PDF should be 0 for negative values
    
    // Test F-distribution
    let f_dist = FDistribution::new(5.0, 10.0);
    assert!(f_dist.mean() > 1.0); // Should be > 1 for df2 > 2
    assert_eq!(f_dist.pdf(-1.0), 0.0); // PDF should be 0 for negative values
    
    // Test Binomial distribution
    let binomial = Binomial::new(10, 0.3).unwrap();
    assert_eq!(binomial.mean(), 3.0);
    assert_eq!(binomial.variance(), 2.1);
    
    // PMF should sum to 1
    let sum: f64 = (0..=10).map(|k| binomial.pmf(k)).sum();
    assert!((sum - 1.0).abs() < 1e-10);
    
    // Test Poisson distribution
    let poisson = Poisson::new(3.0).unwrap();
    assert_eq!(poisson.mean(), 3.0);
    assert_eq!(poisson.variance(), 3.0);
    assert!(poisson.pmf(3) > 0.0);
}

#[test]
fn test_nonparametric_tests() {
    // Test Mann-Whitney U test
    let group1 = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let group2 = vec![6.0, 7.0, 8.0, 9.0, 10.0];
    let result = mann_whitney_u_test(&group1, &group2, AlternativeHypothesis::TwoSided).unwrap();
    
    assert_eq!(result.test_name, "Mann-Whitney U test");
    assert!(result.reject_null); // Groups are clearly different
    assert!(result.effect_size.is_some());
    assert!(result.additional_info.contains_key("u1"));
    assert!(result.additional_info.contains_key("u2"));
    
    // Test Wilcoxon signed-rank test
    let before = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let after = vec![2.0, 3.0, 4.0, 5.0, 6.0]; // All increased by 1
    let result = wilcoxon_signed_rank_test(&before, &after, AlternativeHypothesis::TwoSided).unwrap();
    
    assert_eq!(result.test_name, "Wilcoxon signed-rank test");
    assert!(result.effect_size.is_some());
    assert!(result.additional_info.contains_key("w_plus"));
    assert!(result.additional_info.contains_key("w_minus"));
    
    // Test Kruskal-Wallis test
    let group1 = vec![1.0, 2.0, 3.0];
    let group2 = vec![4.0, 5.0, 6.0];
    let group3 = vec![7.0, 8.0, 9.0];
    let groups = vec![group1.as_slice(), group2.as_slice(), group3.as_slice()];
    let result = kruskal_wallis_test(&groups).unwrap();
    
    assert_eq!(result.test_name, "Kruskal-Wallis test");
    assert!(result.degrees_of_freedom.is_some());
    assert!(result.effect_size.is_some());
    assert!(result.additional_info.contains_key("eta_squared"));
    
    // Test Friedman test
    let subject_data = vec![
        vec![1.0, 2.0, 3.0],
        vec![2.0, 3.0, 4.0],
        vec![3.0, 4.0, 5.0],
    ];
    let result = friedman_test(&subject_data).unwrap();
    
    assert_eq!(result.test_name, "Friedman test");
    assert!(result.additional_info.contains_key("kendalls_w"));
    
    // Test Kolmogorov-Smirnov two-sample test
    let sample1 = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let sample2 = vec![6.0, 7.0, 8.0, 9.0, 10.0];
    let result = ks_two_sample_test(&sample1, &sample2, AlternativeHypothesis::TwoSided).unwrap();
    
    assert_eq!(result.test_name, "Kolmogorov-Smirnov two-sample test");
    assert!(result.statistic > 0.0);
    
    // Test runs test
    let sequence = vec![true, false, true, false, true, false];
    let result = runs_test(&sequence).unwrap();
    
    assert_eq!(result.test_name, "Runs test for randomness");
    assert!(result.additional_info.contains_key("n_runs"));
    assert!(result.additional_info.contains_key("expected_runs"));
}

#[test]
fn test_bootstrap_and_permutation() {
    // Test bootstrap confidence interval
    let data = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0];
    
    // Bootstrap CI for the mean
    let (lower, upper) = bootstrap_confidence_interval(
        &data, 
        |sample| sample.iter().sum::<f64>() / sample.len() as f64,
        0.95,
        100 // Use fewer samples for faster testing
    ).unwrap();
    
    let actual_mean = data.iter().sum::<f64>() / data.len() as f64;
    assert!(lower < actual_mean && actual_mean < upper);
    
    // Test permutation test
    let group1 = vec![1.0, 2.0, 3.0];
    let group2 = vec![4.0, 5.0, 6.0];
    
    let result = permutation_test(
        &group1,
        &group2,
        |g1, g2| {
            let mean1 = g1.iter().sum::<f64>() / g1.len() as f64;
            let mean2 = g2.iter().sum::<f64>() / g2.len() as f64;
            mean1 - mean2
        },
        100, // Use fewer permutations for faster testing
        AlternativeHypothesis::TwoSided,
    ).unwrap();
    
    assert_eq!(result.test_name, "Permutation test");
    assert!(result.additional_info.contains_key("n_permutations"));
}

#[test]
fn test_descriptive_statistics() {
    // Test comprehensive descriptive statistics
    let data = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 100.0]; // Include outlier
    let summary = describe(&data).unwrap();
    
    assert_eq!(summary.count, 11);
    assert!((summary.mean - 14.09).abs() < 0.1); // Approximate due to outlier
    assert_eq!(summary.min, 1.0);
    assert_eq!(summary.max, 100.0);
    assert!(summary.skewness > 0.0); // Should be positively skewed due to outlier
    assert!(summary.kurtosis > 0.0); // Should have positive excess kurtosis
    
    // Check quartiles
    assert!(summary.quartiles.q1 < summary.quartiles.q2);
    assert!(summary.quartiles.q2 < summary.quartiles.q3);
    
    // Check confidence intervals
    assert!(summary.confidence_intervals.ci_95.0 < summary.confidence_intervals.ci_95.1);
    assert!(summary.confidence_intervals.ci_90.0 < summary.confidence_intervals.ci_99.0);
    
    // Check outlier detection
    assert!(!summary.outliers.iqr_outliers.is_empty());
    assert!(summary.outliers.iqr_outliers.contains(&100.0));
    
    // Test percentile calculation
    let sorted_data = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    assert_eq!(percentile(&sorted_data, 0.0).unwrap(), 1.0);
    assert_eq!(percentile(&sorted_data, 50.0).unwrap(), 3.0);
    assert_eq!(percentile(&sorted_data, 100.0).unwrap(), 5.0);
    
    // Test correlation functions
    let x = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let y = vec![2.0, 4.0, 6.0, 8.0, 10.0];
    
    let pearson = pearson_correlation(&x, &y).unwrap();
    assert!((pearson - 1.0).abs() < 1e-10); // Perfect correlation
    
    let spearman = spearman_correlation(&x, &y).unwrap();
    assert!((spearman - 1.0).abs() < 1e-10); // Perfect rank correlation
    
    // Test correlation matrix
    let data_matrix = vec![
        vec![1.0, 2.0, 3.0],
        vec![2.0, 4.0, 6.0],
        vec![1.0, 3.0, 2.0],
    ];
    let corr_matrix = correlation_matrix(&data_matrix).unwrap();
    
    // Diagonal should be 1.0
    assert!((corr_matrix[0][0] - 1.0).abs() < 1e-10);
    assert!((corr_matrix[1][1] - 1.0).abs() < 1e-10);
    assert!((corr_matrix[2][2] - 1.0).abs() < 1e-10);
    
    // Matrix should be symmetric
    assert!((corr_matrix[0][1] - corr_matrix[1][0]).abs() < 1e-10);
    
    // Test covariance matrix
    let cov_matrix = covariance_matrix(&data_matrix).unwrap();
    assert!(cov_matrix.len() == 3);
    assert!(cov_matrix[0].len() == 3);
}

#[test]
fn test_statistical_analyzer() {
    // Create test DataFrame
    let mut df = DataFrame::new();
    
    df.add_column("x1".to_string(), 
        Series::new(vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0], 
                   Some("x1".to_string())).unwrap()
    ).unwrap();
    
    df.add_column("x2".to_string(), 
        Series::new(vec![2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0], 
                   Some("x2".to_string())).unwrap()
    ).unwrap();
    
    df.add_column("x3".to_string(), 
        Series::new(vec![1.0, 3.0, 2.0, 5.0, 4.0, 7.0, 6.0, 9.0, 8.0, 10.0], 
                   Some("x3".to_string())).unwrap()
    ).unwrap();
    
    let analyzer = StatisticalAnalyzer::new();
    
    // Test column analysis
    let summary = analyzer.analyze_column(&df, "x1").unwrap();
    assert_eq!(summary.count, 10);
    assert_eq!(summary.mean, 5.5);
    assert_eq!(summary.min, 1.0);
    assert_eq!(summary.max, 10.0);
    
    // Test correlation analysis
    let pearson_corr = analyzer.correlate_columns(&df, "x1", "x2", CorrelationMethod::Pearson).unwrap();
    assert!((pearson_corr - 1.0).abs() < 1e-10); // Perfect correlation
    
    let spearman_corr = analyzer.correlate_columns(&df, "x1", "x3", CorrelationMethod::Spearman).unwrap();
    assert!(spearman_corr > 0.5); // Should have positive correlation
    
    // Test hypothesis testing
    let test_result = analyzer.test_columns(
        &df, "x1", "x2", 
        HypothesisTestType::TTest, 
        AlternativeHypothesis::TwoSided
    ).unwrap();
    assert!(test_result.test_name.contains("t-test"));
    
    // Test correlation matrix
    let columns = vec!["x1".to_string(), "x2".to_string(), "x3".to_string()];
    let matrix = analyzer.correlation_matrix(&df, &columns, CorrelationMethod::Pearson).unwrap();
    assert_eq!(matrix.len(), 3);
    assert_eq!(matrix[0].len(), 3);
    
    // Test outlier detection
    let outliers = analyzer.detect_outliers(&df, "x1", OutlierMethod::ZScore).unwrap();
    assert!(outliers.is_empty()); // No outliers in this regular data
}

#[test]
fn test_edge_cases_and_error_handling() {
    // Test with empty data
    let empty_data: Vec<f64> = vec![];
    assert!(describe(&empty_data).is_err());
    assert!(pearson_correlation(&empty_data, &empty_data).is_err());
    
    // Test with mismatched lengths
    let x = vec![1.0, 2.0, 3.0];
    let y = vec![1.0, 2.0];
    assert!(pearson_correlation(&x, &y).is_err());
    assert!(independent_ttest(&x, &y, AlternativeHypothesis::TwoSided, true).is_err());
    
    // Test with single element
    let single = vec![1.0];
    assert!(describe(&single).is_ok()); // Should work for describe
    assert!(pearson_correlation(&single, &single).is_err()); // Should fail for correlation
    
    // Test with constant data (zero variance)
    let constant = vec![5.0, 5.0, 5.0, 5.0, 5.0];
    let summary = describe(&constant).unwrap();
    assert_eq!(summary.std, 0.0);
    assert_eq!(summary.variance, 0.0);
    
    // Test percentile edge cases
    let data = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    assert!(percentile(&data, -1.0).is_err()); // Invalid percentile
    assert!(percentile(&data, 101.0).is_err()); // Invalid percentile
    
    // Test distribution edge cases
    let normal = Normal::new(0.0, 1.0);
    assert!(normal.inverse_cdf(0.0).is_nan()); // Should return NaN for edge cases
    assert!(normal.inverse_cdf(1.0).is_nan());
    
    // Test hypothesis test edge cases
    let identical_groups = vec![1.0, 2.0, 3.0];
    let result = independent_ttest(&identical_groups, &identical_groups, AlternativeHypothesis::TwoSided, true).unwrap();
    assert!((result.statistic).abs() < 1e-10); // t-statistic should be approximately 0
    assert!(result.p_value > 0.05); // Should not reject null
}

#[test]
fn test_statistical_consistency() {
    // Test that different methods give consistent results where expected
    let data1 = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let data2 = vec![6.0, 7.0, 8.0, 9.0, 10.0];
    
    // Compare parametric and non-parametric tests
    let t_test_result = independent_ttest(&data1, &data2, AlternativeHypothesis::TwoSided, true).unwrap();
    let mann_whitney_result = mann_whitney_u_test(&data1, &data2, AlternativeHypothesis::TwoSided).unwrap();
    
    // Both should reject the null hypothesis (groups are different)
    assert!(t_test_result.reject_null);
    assert!(mann_whitney_result.reject_null);
    
    // Compare ANOVA and Kruskal-Wallis
    let groups = vec![data1.as_slice(), data2.as_slice()];
    let anova_result = one_way_anova(&groups).unwrap();
    let kw_result = kruskal_wallis_test(&groups).unwrap();
    
    // Both should reject the null hypothesis
    assert!(anova_result.reject_null);
    assert!(kw_result.reject_null);
    
    // Test relationship between one-sample and paired t-tests
    let before = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let after = vec![2.0, 3.0, 4.0, 5.0, 6.0];
    let differences: Vec<f64> = before.iter().zip(after.iter()).map(|(&b, &a)| b - a).collect();
    
    let paired_result = paired_ttest(&before, &after, AlternativeHypothesis::TwoSided).unwrap();
    let one_sample_result = one_sample_ttest(&differences, 0.0, AlternativeHypothesis::TwoSided).unwrap();
    
    // Results should be identical (paired t-test is one-sample t-test on differences)
    assert!((paired_result.statistic - one_sample_result.statistic).abs() < 1e-10);
    assert!((paired_result.p_value - one_sample_result.p_value).abs() < 1e-10);
}

#[test]
fn test_effect_size_interpretations() {
    use pandrs::stats::hypothesis::EffectSize;
    
    // Test Cohen's d interpretations
    let small_effect = EffectSize::CohensD(0.3);
    assert_eq!(small_effect.interpretation(), "Small");
    
    let medium_effect = EffectSize::CohensD(0.6);
    assert_eq!(medium_effect.interpretation(), "Medium");
    
    let large_effect = EffectSize::CohensD(1.0);
    assert_eq!(large_effect.interpretation(), "Large");
    
    // Test correlation interpretations
    let small_correlation = EffectSize::PearsonR(0.2);
    assert_eq!(small_correlation.interpretation(), "Small");
    
    let medium_correlation = EffectSize::PearsonR(0.4);
    assert_eq!(medium_correlation.interpretation(), "Medium");
    
    let large_correlation = EffectSize::PearsonR(0.6);
    assert_eq!(large_correlation.interpretation(), "Large");
    
    // Test eta-squared interpretations
    let small_eta = EffectSize::EtaSquared(0.005);
    assert_eq!(small_eta.interpretation(), "Small");
    
    let medium_eta = EffectSize::EtaSquared(0.03);
    assert_eq!(medium_eta.interpretation(), "Medium");
    
    let large_eta = EffectSize::EtaSquared(0.1);
    assert_eq!(large_eta.interpretation(), "Large");
}