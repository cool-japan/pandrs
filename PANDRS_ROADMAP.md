# PandRS Roadmap - Implementation Plan for pandas-equivalent Functionality

This roadmap serves as a guideline for implementing Rust functionality inspired by Python's Pandas library.

## Currently Implemented Features

- Series (1-dimensional array) and DataFrame (2-dimensional table) data structures
- Support for missing values (NA)
- Grouping operations
- Row labeling with indexes
- CSV/JSON reading and writing
- Parquet data format support (dependencies added, implementation to be expanded)
- Basic operations (filtering, sorting, joining, etc.)
- Aggregation functions for numeric data
- Basic time series data processing
- Pivot tables
- Text-based visualization
- Parallel processing support
- Categorical data type
- Multi-level indexes
- String pool optimization
- High-performance column-oriented storage implementation
- Statistical functions (descriptive statistics, correlation/covariance, t-tests, ANOVA, non-parametric tests, chi-square tests, regression analysis, sampling)

## Short-term Implementation Goals (1-3 months)

### Enhancement and Expansion of Statistical Functions (May-June 2024)

1. **Expansion of Existing Statistical Module (stats/)**
   - âœ… Descriptive statistics functions (sample variance/standard deviation, quantiles)
   - âœ… Covariance and correlation analysis
   - âœ… Hypothesis testing (t-tests)
   - âœ… Basic regression analysis (simple/multiple regression, least squares method)
   - âœ… Sampling methods (bootstrap)
   - âœ… Implementation of analysis of variance (one-way ANOVA)
   - âœ… Non-parametric tests (Mann-Whitney U test)
   - âœ… Implementation of chi-square tests
   - âœ… Enhancement of confidence intervals and prediction intervals

2. **Strengthening Integration with Existing Features**
   - âœ… Providing independent API functions
   - âœ… Organizing public API interfaces (publishing linear_regression functions, etc.)
   - âœ… Adding statistical methods to DataFrame and Series
   - âœ… Interface design for integration with parallel processing
   - âœ… Integration with optimized implementation (optimized/)
   - Specialized statistical processing for categorical data

3. **Machine Learning Evaluation Metrics Module**
   - âœ… Regression model evaluation metrics (MSE, MAE, RMSE, RÂ² score)
   - âœ… Classification model evaluation metrics (accuracy, precision, recall, F1 score)
   - âœ… Error handling and documentation

### Expansion of Data Structures and Operations

1. âœ… **MultiIndex (Multi-level Index)**
   - âœ… Hierarchical index structure
   - âœ… Level-based data access
   - âœ… Index swapping operations

2. âœ… **Categorical Data Type**
   - âœ… Efficient representation of categorical data
   - âœ… Support for ordered categorical data
   - âœ… Categorical data operations (transformation, aggregation, etc.)

3. âœ… **Expansion of DataFrame Operations**
   - âœ… Function application features equivalent to `apply`/`applymap`
   - âœ… Conditional replacement (`where`/`mask`/`replace`)
   - âœ… Improved detection and removal of duplicate rows

### Enhancement of Data Input/Output

1. âœ… **Excel Support**
   - âœ… Reading and writing xlsx files
   - âœ… Sheet specification and operations
   - âœ… Basic Excel output functionality

2. âœ… **SQL Interface**
   - âœ… Reading from SQLite (queries using SQL statements)
   - âœ… Writing to SQLite
   - âœ… Options for adding to/replacing existing tables

3. âœ… **Parquet and Column-Oriented Format Support**
   - âœ… Addition of dependencies (arrow 54.3.1, parquet 54.3.1)
   - âœ… Reading and writing Parquet files
   - âœ… Compression options (Snappy, GZIP, Brotli, LZO, LZ4, Zstd)
   - âœ… Integration with column-oriented data structures

### Enhancement of Time Series Data Processing

1. âœ… **Strengthening Periodic Indexes**
   - âœ… Custom frequencies (business days, etc.)
   - âœ… Support for quarterly and fiscal year calculations
   - âœ… Extension of calendar functionality (chrono-tz 0.10.3)

2. âœ… **Time Series-Specific Operations**
   - âœ… Seasonal decomposition
   - âœ… Expanded types of moving averages
   - âœ… Optimization of time series shift and difference operations

## Medium-term Implementation Goals (4-8 months)

### Advanced Analysis Features

1. âœ… **Window Operations**
   - âœ… Fixed, expanding, and variable window processing
   - âœ… Window aggregation functions
   - âœ… Diversification of rolling statistics

2. **Enhanced Statistical Functions**
   - âœ… Correlation coefficients and covariance
   - âœ… Hypothesis testing (t-tests)
   - âœ… Sampling and random number generation (rand 0.9.0)
   - âœ… Basic regression analysis (simple/multiple regression)
   - ðŸ”„ Advanced statistical methods (expanded hypothesis testing, non-parametric tests)

3. âœ… **Enhanced String Operations**
   - âœ… Regular expression-based search and replacement (regex 1.10.2)
   - âœ… Optimization of string vector operations
   - âœ… Text processing utilities

### Data Visualization Enhancement

1. âœ… **Integration with Plotters**
   - âœ… Integration of high-quality visualization library (plotters v0.3.7)
   - âœ… Support for PNG and SVG output formats
   - âœ… Expanded graph types (line, bar, scatter, histogram, area charts)
   - âœ… Customization options (size, color, grid, legend)
   - ðŸ”„ Direct plotting from DataFrame/Series (partially implemented)

2. **Interactive Visualization**
   - ðŸ”„ Browser visualization with WebAssembly support (initial stage)
   - Dashboard functionality
   - Dynamic graph generation

### Memory and Performance Optimization

1. âœ… **Memory Usage Optimization**
   - âœ… Addition of zero-copy operations
   - âœ… Optimization of column-oriented storage
   - âœ… Disk-based processing for large datasets

2. âœ… **Enhanced Parallel Processing**
   - âœ… DataFrame-level parallel processing (rayon 1.9.0)
   - âœ… Parallel optimization of operation chains
   - âœ… GPU acceleration with CUDA (up to 20x speedup)

3. âœ… **Codebase Optimization**
   - âœ… Function-based file splitting for OptimizedDataFrame
   - âœ… Optimal division into core functionality, column operations, data operations, etc.
   - âœ… Re-export with API compatibility assurance
   - âœ… Module structure reorganization (Stage 1 & 2)
     - âœ… Creation of core/ directory with fundamental data structures
     - âœ… Creation of compute/ directory with computation functionality
     - âœ… Creation of storage/ directory with storage engines
     - âœ… Restructuring of dataframe/ and series/ directories
     - âœ… Implementation of backward compatibility layers
   - ðŸ”„ Module structure reorganization (Stage 3)
     - ðŸ”„ Feature module reorganization for stats/, ml/, temporal/, and vis/
     - Specialized module structures for advanced features
     - Documentation updates

## Long-term Implementation Goals (9+ months)

### Advanced Data Science Features

1. **Integration with Machine Learning**
   - âœ… Data transformation pipeline equivalent to scikit-learn
   - âœ… Feature engineering functionality
     - âœ… Polynomial feature generation
     - âœ… Binning (discretization)
     - âœ… Missing value imputation
     - âœ… Feature selection
   - âœ… Utilities for model training and evaluation
     - âœ… Linear regression and logistic regression models
     - âœ… Model selection (cross-validation, grid search)
     - âœ… Model evaluation metrics
     - âœ… Model saving and loading

2. **Dimensionality Reduction and Exploratory Data Analysis**
   - âœ… Implementation of PCA, t-SNE, etc.
     - âœ… Principal Component Analysis (PCA)
     - âœ… t-Distributed Stochastic Neighbor Embedding (t-SNE)
   - âœ… Clustering functionality
     - âœ… k-means clustering
     - âœ… Hierarchical clustering
     - âœ… DBSCAN (density-based clustering)
   - âœ… Anomaly detection
     - âœ… Isolation Forest
     - âœ… LOF (Local Outlier Factor)
     - âœ… One-Class SVM

3. ðŸ”„ **Large-scale Data Processing**
   - âœ… Chunk processing functionality
   - ðŸ”„ Streaming data support
   - Integration with distributed processing frameworks

### Ecosystem Integration

1. âœ… **Python Bindings**
   - âœ… Python module creation using PyO3
   - âœ… Interoperability with numpy and pandas
   - âœ… Jupyter Notebook support

2. **Integration with R Language**
   - Interoperability between R and Rust
   - tidyverse-style interface

3. **Database Integration**
   - Connectors for major databases
   - Query optimizer
   - ORM-like functionality

## Implementation Approach

1. **Incremental Implementation Strategy**
   - First design the API and create doc tests
   - Implement basic functionality simply
   - Optimize performance incrementally

2. **Usability Focus**
   - Intuitive API for those familiar with Python's pandas
   - API design leveraging Rust's strengths in type safety
   - Comprehensive documentation and examples

3. **Test Strategy**
   - Unit tests for each feature
   - Compatibility tests with pandas
   - Performance tests through benchmarks

## Next Steps

1. **Community Building**
   - Establishing contribution guidelines
   - Organizing milestones and issues
   - Creating issues for beginners

2. **Documentation Enhancement**
   - Expanding API documentation
   - Creating tutorials and cookbooks
   - Use case gallery

3. âœ… **Updating Dependencies**
   - âœ… Updating all dependencies to the latest versions (as of April 2024)
   - âœ… Ensuring compatibility with the Rust 2023 ecosystem
   - âœ… Updates for security and performance improvements
   - âœ… Adapting to rand 0.9.0 API changes (`gen_range` â†’ `random_range`)
   - âœ… Adapting to new API for Parquet compression constants

4. **Packaging**
   - Publication and distribution on crates.io
   - Versioning strategy
   - Dependency management

## Key Dependencies (Latest as of April 2024)

```toml
[dependencies]
num-traits = "0.2.19"        # Numeric type trait support
thiserror = "2.0.12"         # Error handling
serde = { version = "1.0.219", features = ["derive"] }  # Serialization
serde_json = "1.0.114"       # JSON processing
chrono = "0.4.40"            # Date and time processing
regex = "1.10.2"             # Regular expressions
csv = "1.3.1"                # CSV processing
rayon = "1.9.0"              # Parallel processing
lazy_static = "1.5.0"        # Lazy initialization
rand = "0.9.0"               # Random number generation
tempfile = "3.8.1"           # Temporary files
textplots = "0.8.7"          # Text-based visualization
chrono-tz = "0.10.3"         # Timezone processing
parquet = "54.3.1"           # Parquet file support
arrow = "54.3.1"             # Arrow format support
```

---

This roadmap outlines PandRS's goal to provide functionality equivalent to Python's pandas library while leveraging Rust's characteristics to create a high-performance data analysis library. Implementation priorities should be adjusted according to community interests and needs.